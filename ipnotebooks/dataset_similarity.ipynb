{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sumformulas = 6046\n",
      "Number of documents = 1421\n"
     ]
    }
   ],
   "source": [
    "dnodes_file = '/home/katya/Dropbox/metabolite annotation/170720 all .8 0 .8/Dnodes.csv'\n",
    "sim_file = '/home/katya/Dropbox/metabolite annotation/170720 all .8 0 .8/dataset_similarity.csv'\n",
    "\n",
    "# IF THERE IS A NEED TO SAVE GENERATED CORPORA AND MODELS, if not put None\n",
    "corpora_dir = '/home/katya/Dropbox/metabolite annotation/170720 all .8 0 .8/corpora'\n",
    "model_dir = '/home/katya/Dropbox/metabolite annotation/170720 all .8 0 .8/models'\n",
    "sim_dir = '/home/katya/Dropbox/metabolite annotation/170720 all .8 0 .8/sim_index'\n",
    "misc_dir = '/home/katya/Dropbox/metabolite annotation/170720 all .8 0 .8/mics'\n",
    "\n",
    "# SET THE MODELS TO BE TRAINED\n",
    "tfidf = True\n",
    "lsi = True\n",
    "lda = False\n",
    "\n",
    "# Number of topics for LSI and LDA\n",
    "n_topics = 100\n",
    "\n",
    "#Threshold for molecule values\n",
    "t = 0.5\n",
    "# Threshold for molecule frequencies\n",
    "f = 0.8\n",
    "\n",
    "val_t = int((1-float(t))*100)\n",
    "\n",
    "# CREATE A CORPUS\n",
    "corpus = []\n",
    "doc_ids = []\n",
    "molecule_names = []\n",
    "first = True\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "if corpora_dir and (not os.path.exists(corpora_dir)): os.makedirs(corpora_dir)\n",
    "if model_dir and (not os.path.exists(model_dir)): os.makedirs(model_dir)\n",
    "if sim_dir and (not os.path.exists(sim_dir)): os.makedirs(sim_dir)\n",
    "if misc_dir and (not os.path.exists(misc_dir)): os.makedirs(misc_dir)\n",
    "\n",
    "dictionary = {}\n",
    "\n",
    "with open(dnodes_file, 'r') as csvfile:\n",
    "    rowreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in rowreader:\n",
    "        if first: \n",
    "            molecule_names = row[44:-2]\n",
    "            print('Number of sumformulas = ' + str(len(molecule_names)))\n",
    "            first = False\n",
    "        else:\n",
    "            doc_ids.append(row[0])\n",
    "            molecule_values =  [int((1-float(mv))*100) for mv in row[44:-2]]\n",
    "            ds = []\n",
    "            for i in range(0,len(molecule_names)):\n",
    "                if molecule_values[i]>val_t:\n",
    "                        ds.append((i,molecule_values[i]))\n",
    "            corpus.append(ds)\n",
    "\n",
    "print('Number of documents = %d' % len(corpus))\n",
    "\n",
    "if corpora_dir: corpora.MmCorpus.serialize(os.path.join(corpora_dir,'corpus.mm'), corpus)\n",
    "    \n",
    "dictionary = {i:v for (i,v) in enumerate(molecule_names)}\n",
    "\n",
    "if misc_dir:\n",
    "    with open(os.path.join(misc_dir,'dataset_names.pkl'), 'wb') as f: pickle.dump(doc_ids, f)\n",
    "    with open(os.path.join(misc_dir,'dictionary.pkl'), 'wb') as f: pickle.dump(dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# RUN MODELING\n",
    "\n",
    "from gensim import models\n",
    "\n",
    "if tfidf:\n",
    "    tfidf_model = gensim.models.TfidfModel(corpus, id2word=dictionary)\n",
    "    tfidf_corpus = tfidf_model[corpus]\n",
    "    if model_dir: tfidf_model.save(os.path.join(model_dir,'model.tfidf'))\n",
    "    if corpora_dir: corpora.MmCorpus.serialize(os.path.join(corpora_dir,'corpus_tfidf.mm'), tfidf_corpus)\n",
    "    tfidf_model = None\n",
    "    \n",
    "    if lsi:\n",
    "        lsi_model = gensim.models.LsiModel(tfidf_corpus, id2word=dictionary, num_topics=n_topics)\n",
    "        lsi_corpus = lsi_model[tfidf_corpus]\n",
    "        if model_dir: lsi_model.save(os.path.join(model_dir,'model.lsi'))\n",
    "        if corpora_dir:corpora.MmCorpus.serialize(os.path.join(corpora_dir,'corpus_lsi.mm'), lsi_corpus)\n",
    "        lsi_model = None\n",
    "if lda:\n",
    "    lda_model = gensim.models.ldamulticore.LdaMulticore(corpus, num_topics=n_topics, id2word = dictionary, iterations=3000, passes = 10, workers=4)\n",
    "    lda_corpus = lda_model[corpus]\n",
    "    if corpora_dir:corpora.MmCorpus.serialize(os.path.join(corpora_dir,'corpus_lda.mm'), lda_corpus)\n",
    "    if model_dir: lda_model.save(os.path.join(model_dir,'model.lda'))\n",
    "    lda_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# RUN SIMILARITY MODELING\n",
    "\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "\n",
    "if tfidf:\n",
    "    tfidf_index = MatrixSimilarity(tfidf_corpus)\n",
    "    tfidf_sims = tfidf_index[tfidf_corpus]\n",
    "    if sim_dir: tfidf_index.save(os.path.join(sim_dir,'tfidf.index'))\n",
    "\n",
    "if lsi:\n",
    "    lsi_index = MatrixSimilarity(lsi_corpus)\n",
    "    lsi_sims = tfidf_index[lsi_corpus]\n",
    "    if sim_dir: lsi_index.save(os.path.join(sim_dir,'lsi.index'))\n",
    "        \n",
    "if lda:\n",
    "    lda_index = MatrixSimilarity(lda_corpus)\n",
    "    lda_sims = tfidf_index[lda_corpus]\n",
    "    if sim_dir: lda_index.save(os.path.join(sim_dir,'lda.index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# OUTPUT SIMILARITY RESULTS INTO FILE\n",
    "\n",
    "simoutput_file = open(sim_file, 'w')\n",
    "\n",
    "simoutput_file.write('ID1,ID2,tfidf_similarity,lsi_similarity,lda_similarity\\n')\n",
    "counter = 0\n",
    "for i in range(0,len(doc_ids)):\n",
    "    for j in range(i+1,len(doc_ids)):\n",
    "        simoutput_file.write(doc_ids[i]+',')\n",
    "        simoutput_file.write(doc_ids[j])\n",
    "\n",
    "        if tfidf: dist_tfidf = tfidf_sims[i][j]\n",
    "        if lsi: dist_lsi = (lsi_sims[i][j]+1)/2\n",
    "        if lda: dist_lda = lda_sims[i][j]\n",
    "\n",
    "        if tfidf: simoutput_file.write(','+str(dist_tfidf))\n",
    "        else: simoutput_file.write(',-')\n",
    "        if lsi: simoutput_file.write(','+str(dist_lsi))\n",
    "        else: simoutput_file.write(',-')\n",
    "        if lda: simoutput_file.write(','+str(dist_lda))\n",
    "        else: simoutput_file.write(',-')\n",
    "        simoutput_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
